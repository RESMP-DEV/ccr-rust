# yaml-language-server: $schema=
# CCR-Rust v0.3.0 — Production Hardening & Remaining Features
#
# NOTE: Phases 1-4 from v0.2.0 are COMPLETED.
# - Transformer infrastructure ✓
# - Anthropic → OpenAI request translation ✓
# - OpenAI → Anthropic response translation ✓
# - Router integration ✓
#
# This file contains the remaining work for v0.3.0.
#
# Task execution from repo root:
#   uv run alphaheng tasks add contrib/ccr-rust/tasks/ccr_rust_v02.yaml
#   uv run alphaheng coordinator --local-workers 10

tasks:
  # ==========================================================================
  # Phase 1: Think-Tag Stripping (P0)
  # ==========================================================================

  - name: ccr-think-tag-transformer
    priority: P0
    prompt: |
      Create `contrib/ccr-rust/src/transform/thinktag.rs`:

      Implement `ThinkTagTransformer` to strip reasoning tokens:

      1. On response, find content matching `<think>...</think>` or `<thinking>...</thinking>`
      2. Remove the think blocks from text content
      3. Optionally: preserve in a separate field for logging/audit

      Options (from TransformerEntry):
      - `strip_patterns: ["<think>", "<thinking>", "<reasoning>"]`
      - `preserve_in_metadata: bool` (default: false)

      Register as "thinktag" in the TransformerRegistry in `src/transformer.rs`.

      Add unit tests for various tag patterns.
    verify_command: grep -q "ThinkTagTransformer\|thinktag" contrib/ccr-rust/src/transformer.rs

  # ==========================================================================
  # Phase 2: Fix EWMA Backoff Tests (P0)
  # ==========================================================================

  - name: ccr-fix-ewma-backoff-tests
    priority: P0
    prompt: |
      Fix the 2 failing EWMA backoff tests in `contrib/ccr-rust/src/config.rs`:

      1. `ewma_backoff_fast_tier_scales_down` - FAILED
      2. `ewma_backoff_never_below_base` - FAILED

      Current issue: The backoff calculation logic needs adjustment.

      Review the `backoff_duration_with_ewma` function and fix the scaling logic
      so that:
      - Fast tiers (low EWMA latency) get shorter backoffs
      - Backoff should never go below the configured base

      Update the tests or fix the implementation to match the expected behavior.
    verify_command: "cd contrib/ccr-rust && cargo test backoff_tests --no-fail-fast 2>&1 | grep -q 'test result: ok'"

  # ==========================================================================
  # Phase 3: Production Hardening (P1)
  # ==========================================================================

  - name: ccr-graceful-shutdown
    priority: P1
    prompt: |
      Update `contrib/ccr-rust/src/main.rs` for graceful shutdown:

      1. Install SIGINT/SIGTERM handlers using `tokio::signal`
      2. Create a `shutdown_tx: broadcast::Sender<()>` channel
      3. Pass `shutdown_rx` to the server via `axum::serve(...).with_graceful_shutdown(...)`
      4. Track active streams in `AppState` with an `AtomicUsize`
      5. On shutdown signal:
         - Stop accepting new requests (502 for new connections)
         - Wait up to 30s for active streams to complete
         - Force-close remaining streams after timeout

      Add `--shutdown-timeout` CLI flag (default: 30s).
    verify_command: grep -q "with_graceful_shutdown" contrib/ccr-rust/src/main.rs

  - name: ccr-request-cancellation
    priority: P1
    dependencies: [ccr-graceful-shutdown]
    prompt: |
      Update `contrib/ccr-rust/src/router.rs` for request cancellation:

      1. Accept a `CancellationToken` (from tokio-util) in streaming handlers
      2. In the stream forwarding loop, select on:
         - Next chunk from upstream
         - Cancellation signal
         - Client disconnect (tx.closed())
      3. On cancellation or client disconnect:
         - Abort the upstream request (reqwest supports abort)
         - Clean up metrics (decrement active_streams)
         - Log the cancellation reason

      Add `tokio-util` dependency with `sync` feature.
    verify_command: grep -q "CancellationToken" contrib/ccr-rust/src/router.rs

  - name: ccr-rate-limit-handling
    priority: P1
    prompt: |
      Create `contrib/ccr-rust/src/ratelimit.rs`:

      1. `RateLimitState` struct tracking per-tier rate limit info:
         - `remaining: Option<u32>` (from x-ratelimit-remaining header)
         - `reset_at: Option<Instant>` (from x-ratelimit-reset header)
         - `backoff_until: Option<Instant>` (exponential backoff on 429)

      2. In router, before trying a tier:
         - Check if `backoff_until` is in the future → skip tier
         - Check if `remaining == 0` and `reset_at` is in the future → skip tier

      3. On 429 response:
         - Parse Retry-After header if present
         - Set exponential backoff (min 1s, max 60s, 2x multiplier)
         - Record to `ccr_rate_limit_backoffs_total` metric

      4. On success: update remaining/reset from response headers

      Add `mod ratelimit;` to `src/lib.rs`.
    verify_command: grep -q "RateLimitState" contrib/ccr-rust/src/ratelimit.rs

  # ==========================================================================
  # Phase 4: Additional Transformer Features (P1)
  # ==========================================================================

  - name: ccr-tool-result-translation
    priority: P1
    prompt: |
      Extend the format translation in `contrib/ccr-rust/src/router.rs` to handle
      tool result messages in conversation history:

      Anthropic format:
      ```json
      {"role": "user", "content": [{"type": "tool_result", "tool_use_id": "...", "content": "..."}]}
      ```

      OpenAI format:
      ```json
      {"role": "tool", "tool_call_id": "...", "content": "..."}
      ```

      Update `translate_request_anthropic_to_openai` to:
      1. Detect tool_result blocks in user messages
      2. Split them into separate "tool" role messages for OpenAI
      3. Handle mixed content (text + tool_results in same message)

      Add tests for this translation path.
    verify_command: grep -q "tool_result" contrib/ccr-rust/src/router.rs

  - name: ccr-image-content-translation
    priority: P1
    prompt: |
      Extend the format translation to handle image content:

      Anthropic format:
      ```json
      {"type": "image", "source": {"type": "base64", "media_type": "image/png", "data": "..."}}
      ```

      OpenAI format:
      ```json
      {"type": "image_url", "image_url": {"url": "data:image/png;base64,..."}}
      ```

      Update `normalize_message_content` in `contrib/ccr-rust/src/router.rs` to:
      1. Detect image blocks in content arrays
      2. Convert Anthropic base64 format to OpenAI data URI format
      3. Preserve image blocks when returning array format

      Add tests for image content translation.
    verify_command: grep -q "image_url\|image/png" contrib/ccr-rust/src/router.rs

  # ==========================================================================
  # Phase 5: Testing (P2)
  # ==========================================================================

  - name: ccr-transformer-unit-tests
    priority: P2
    prompt: |
      Expand tests in `contrib/ccr-rust/src/transformer.rs`:

      Add tests for:
      1. `anthropic_to_openai_tool_conversion` - input_schema → parameters
      2. `anthropic_to_openai_tool_choice` - all tool_choice variants
      3. `deepseek_tool_id_generation` - ensure unique IDs
      4. `reasoning_transformer_thinking_extraction` - reasoning_content handling
      5. `chain_response_reversal` - verify responses apply in reverse order

      Use JSON fixtures for complex test cases.
    verify_command: "cd contrib/ccr-rust && cargo test transformer::tests --no-fail-fast 2>&1 | grep -q 'test result: ok'"

  - name: ccr-router-translation-tests
    priority: P2
    prompt: |
      Expand tests in `contrib/ccr-rust/src/router.rs`:

      Add tests for:
      1. `translate_request_no_system` - request without system prompt
      2. `translate_request_array_system` - array-style system prompt
      3. `translate_request_with_tools` - full tool definition conversion
      4. `translate_response_no_choices` - empty choices array
      5. `translate_response_multiple_content_blocks` - text + tool_use
      6. `translate_stream_tool_call_chunks` - streaming tool calls

      Add snapshot testing with `insta` crate for complex JSON.
    verify_command: "cd contrib/ccr-rust && cargo test router::tests --no-fail-fast 2>&1 | grep -E '(passed|test result)'"

  - name: ccr-integration-tests-format-parity
    priority: P2
    prompt: |
      Update `contrib/ccr-rust/tests/test_routing.rs`:

      Add integration tests using wiremock:

      1. `anthropic_request_reaches_openai_format` - verify request body transformation
      2. `openai_response_returns_anthropic_format` - verify response transformation
      3. `streaming_events_transformed` - SSE event format conversion
      4. `reasoning_model_thinking_preserved` - reasoning_content → thinking block
      5. `tool_call_round_trip` - tool definition + tool use + tool result

      Mock an OpenAI-format backend and verify CCR-Rust transforms correctly.
    verify_command: "cd contrib/ccr-rust && cargo test test_routing --no-fail-fast 2>&1 | grep -E '(passed|FAILED)'"

  # ==========================================================================
  # Phase 6: Documentation (P2)
  # ==========================================================================

  - name: ccr-docs-api-reference
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/api.md`:

      Document all API endpoints with examples:

      1. `POST /v1/messages` - Main chat completion endpoint
         - Request format (Anthropic)
         - Response format (Anthropic)
         - Headers: x-ccr-tier, x-ccr-latency

      2. `GET /v1/usage` - Token usage statistics
         - Response format
         - Per-tier breakdown

      3. `GET /v1/latencies` - EWMA latency stats
         - Response format
         - How tiers are reordered

      4. `GET /v1/token-drift` - Token estimation accuracy
         - Response format
         - Alert thresholds

      5. `GET /metrics` - Prometheus endpoint
         - Available metrics list
         - Example Grafana queries

      Include curl examples for each endpoint.
    verify_command: test -f contrib/ccr-rust/docs/api.md

  - name: ccr-docs-transformers
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/transformers.md`:

      Document the transformer system:

      1. **Overview**: What transformers do, when they run

      2. **Configuration**: How to specify transformers in config.json
         - Provider-level: `"transformer": {"use": [...]}`
         - Model-level overrides
         - Tuple syntax with options

      3. **Built-in Transformers**: Table with each transformer
         - Name, description, options
         - Example config for each

      4. **Request/Response Flow**: Diagram showing:
         - Request: Anthropic → transformers → OpenAI → provider
         - Response: Provider → OpenAI → transformers → Anthropic

      5. **Custom Transformers**: Brief note on extending (Rust knowledge required)

      Include JSON config examples for common use cases.
    verify_command: test -f contrib/ccr-rust/docs/transformers.md

  - name: ccr-docs-configuration
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/configuration.md`:

      Comprehensive configuration reference:

      1. **Config File Location**: Paths, environment variables

      2. **Providers Section**: Required and optional fields
         - `name`, `api_base_url`, `api_key`, `models`
         - `transformer` configuration

      3. **Router Section**: Tier routing configuration
         - `default`, `think`, `longContext`
         - `longContextThreshold`
         - `tierRetries` per-tier configuration

      4. **Full Example**: Complete config.json with all options

      5. **Environment Variables**: CCR_CONFIG, API keys

      6. **Migration from Node.js CCR**: Differences, compatibility notes

      Include schema validation notes.
    verify_command: test -f contrib/ccr-rust/docs/configuration.md

  - name: ccr-docs-troubleshooting
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/troubleshooting.md`:

      Common issues and solutions:

      1. **Connection Errors**
         - "Connection refused" - Provider URL, firewall
         - "DNS resolution failed" - Network config
         - SSL/TLS errors - Certificates

      2. **Rate Limiting**
         - 429 responses - Tier backoff behavior
         - Monitoring rate limits via metrics

      3. **Format Translation Issues**
         - Tool calls not working - Check transformer config
         - Missing system prompt - Anthropic vs OpenAI handling
         - Streaming breaks - SSE parsing issues

      4. **Performance Issues**
         - High latency - Check EWMA stats, tier ordering
         - Memory growth - Stream limits, connection pooling
         - Backpressure - Increase buffer size

      5. **Token Drift Alerts**
         - What drift means
         - Acceptable thresholds
         - Debugging high drift

      Include diagnostic commands and metric queries.
    verify_command: test -f contrib/ccr-rust/docs/troubleshooting.md

  - name: ccr-docs-deployment
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/deployment.md`:

      Production deployment guide:

      1. **Building for Production**
         ```bash
         cargo build --release
         ```
         - Binary location, stripping symbols

      2. **Systemd Service**
         - Example unit file
         - Environment file for secrets
         - Logging configuration

      3. **Docker**
         - Dockerfile (multi-stage build)
         - docker-compose example
         - Health check configuration

      4. **Kubernetes**
         - Deployment manifest
         - Service and Ingress
         - ConfigMap for config.json
         - Secret for API keys

      5. **Monitoring**
         - Prometheus scrape config
         - Grafana dashboard JSON
         - Alerting rules

      6. **Security**
         - Running as non-root
         - API key management
         - Network isolation

      Include production-ready configs.
    verify_command: test -f contrib/ccr-rust/docs/deployment.md

  # ==========================================================================
  # Phase 7: Cleanup (P3)
  # ==========================================================================

  - name: ccr-cleanup-dead-code
    priority: P3
    prompt: |
      Address the unused code warnings in ccr-rust:

      1. `src/router.rs`:
         - Remove or use: `object`, `created`, `model` fields in OpenAIResponse
         - Remove or use: `index` in OpenAIChoice
         - Remove or use: `role` in OpenAIResponseMessage
         - Remove or use: `prompt_tokens_details` in OpenAIUsage
         - Use or remove `build_transformer_chain` function

      2. `src/transformer.rs`:
         - Remove or use: `len`, `is_empty` on TransformerChain
         - Remove or use: `get`, `create_with_options`, `build_chain`, `validate_entries`
         - Remove or use: `uuid_nopanic` module

      3. `src/config.rs`:
         - Remove or use: `provider_transformers`, `is_sole_transformer`

      Either integrate these into the codebase or add `#[allow(dead_code)]` with
      a TODO comment explaining future use.
    verify_command: "cd contrib/ccr-rust && cargo check 2>&1 | grep -c 'warning:' | grep -q '^0$' || echo 'Still has warnings'"

  - name: ccr-cleanup-remove-old-sse
    priority: P3
    prompt: |
      Clean up `contrib/ccr-rust/src/sse.rs`:

      The `stream_response` function is no longer used since streaming now goes
      through `stream_response_translated` in router.rs.

      1. Check if `stream_response` is still called anywhere
      2. If not, remove it and its helper functions
      3. Keep only the types and utilities still in use:
         - `StreamVerifyCtx`
         - `extract_usage_from_event`
         - Usage-related tests

      Update `mod.rs` exports if needed.
    verify_command: grep -q "stream_response_translated" contrib/ccr-rust/src/router.rs
