# yaml-language-server: $schema=
# CCR-Rust v0.3.0 — Production Hardening
#
# Atomic task list for AlphaHENG agent swarm.
# Each task = 1 agent = 1 atomic action.
#
# Run from AlphaHENG repo root:
#   uv run alphaheng tasks add contrib/ccr-rust/tasks/ccr_rust_v03_production.yaml
#   uv run alphaheng coordinator --local-workers 20

tasks:
  # ==========================================================================
  # Phase 1: Critical Bug Fixes (P0)
  # ==========================================================================

  - name: ccr-fix-ewma-backoff-fast-tier
    priority: P0
    prompt: |
      Fix the failing test `ewma_backoff_fast_tier_scales_down` in
      `contrib/ccr-rust/src/config.rs`.
      
      The test expects that fast tiers (low EWMA latency) get scaled-down
      backoff delays. Review `backoff_duration_with_ewma` and adjust the
      scaling logic.
      
      Current behavior: Fast tiers may not be scaling correctly.
      Expected: A tier with 50ms EWMA should have shorter backoff than base.
      
      Run: `cd contrib/ccr-rust && cargo test ewma_backoff_fast_tier`
    verify_command: "cd contrib/ccr-rust && cargo test ewma_backoff_fast_tier_scales_down 2>&1 | grep -q 'ok'"

  - name: ccr-fix-ewma-backoff-never-below-base
    priority: P0
    prompt: |
      Fix the failing test `ewma_backoff_never_below_base` in
      `contrib/ccr-rust/src/config.rs`.
      
      The test ensures backoff never goes below the configured base value.
      Review `backoff_duration_with_ewma` and add a floor check.
      
      Add: `std::cmp::max(scaled_backoff, self.base_backoff_ms)`
      
      Run: `cd contrib/ccr-rust && cargo test ewma_backoff_never_below_base`
    verify_command: "cd contrib/ccr-rust && cargo test ewma_backoff_never_below_base 2>&1 | grep -q 'ok'"

  # ==========================================================================
  # Phase 2: Graceful Shutdown (P0)
  # ==========================================================================

  - name: ccr-shutdown-signal-handler
    priority: P0
    prompt: |
      Add signal handlers to `contrib/ccr-rust/src/main.rs`:
      
      1. Import `tokio::signal::ctrl_c` and `tokio::signal::unix::{signal, SignalKind}`
      2. Create an async function `shutdown_signal()` that awaits either:
         - SIGINT (Ctrl+C)
         - SIGTERM (kill)
      3. Log "Received shutdown signal, draining connections..."
      
      ```rust
      async fn shutdown_signal() {
          let ctrl_c = async { ctrl_c().await.expect("failed to listen for ctrl+c") };
          #[cfg(unix)]
          let terminate = async {
              signal(SignalKind::terminate())
                  .expect("failed to install signal handler")
                  .recv()
                  .await;
          };
          #[cfg(not(unix))]
          let terminate = std::future::pending::<()>();
          
          tokio::select! {
              _ = ctrl_c => tracing::info!("Received SIGINT"),
              _ = terminate => tracing::info!("Received SIGTERM"),
          }
      }
      ```
    verify_command: grep -q "shutdown_signal\|SignalKind::terminate" contrib/ccr-rust/src/main.rs

  - name: ccr-shutdown-graceful-serve
    priority: P0
    dependencies: [ccr-shutdown-signal-handler]
    prompt: |
      Update `contrib/ccr-rust/src/main.rs` to use graceful shutdown:
      
      Replace:
      ```rust
      axum::serve(listener, app).await?;
      ```
      
      With:
      ```rust
      axum::serve(listener, app)
          .with_graceful_shutdown(shutdown_signal())
          .await?;
      ```
      
      This ensures in-flight requests complete before the server exits.
    verify_command: grep -q "with_graceful_shutdown" contrib/ccr-rust/src/main.rs

  - name: ccr-shutdown-active-stream-counter
    priority: P0
    dependencies: [ccr-shutdown-graceful-serve]
    prompt: |
      Add active stream tracking to `contrib/ccr-rust/src/router.rs`:
      
      1. Add to `AppState`:
         ```rust
         pub active_streams: Arc<AtomicUsize>,
         ```
      
      2. Update `main.rs` to initialize:
         ```rust
         active_streams: Arc::new(AtomicUsize::new(0)),
         ```
      
      3. In `stream_response_translated`, increment on start:
         ```rust
         state.active_streams.fetch_add(1, Ordering::Relaxed);
         ```
      
      4. Decrement on stream end (in the spawned task's cleanup).
      
      This replaces the global metric counter with state-tracked counting.
    verify_command: grep -q "active_streams.*AtomicUsize" contrib/ccr-rust/src/router.rs

  - name: ccr-shutdown-timeout-cli
    priority: P0
    dependencies: [ccr-shutdown-graceful-serve]
    prompt: |
      Add `--shutdown-timeout` CLI flag to `contrib/ccr-rust/src/main.rs`:
      
      1. Add to Cli struct:
         ```rust
         /// Graceful shutdown timeout in seconds
         #[arg(long, default_value = "30")]
         shutdown_timeout: u64,
         ```
      
      2. Store in AppState or pass to shutdown handler.
      
      3. Log the configured timeout on startup:
         ```rust
         tracing::info!("Shutdown timeout: {}s", cli.shutdown_timeout);
         ```
    verify_command: grep -q "shutdown_timeout\|shutdown-timeout" contrib/ccr-rust/src/main.rs

  # ==========================================================================
  # Phase 3: Request Cancellation (P1)
  # ==========================================================================

  - name: ccr-cancel-add-tokio-util
    priority: P1
    prompt: |
      Add `tokio-util` dependency to `contrib/ccr-rust/Cargo.toml`:
      
      Under `[dependencies]`, add:
      ```toml
      tokio-util = { version = "0.7", features = ["sync"] }
      ```
      
      This provides `CancellationToken` for cooperative cancellation.
    verify_command: grep -q 'tokio-util.*sync' contrib/ccr-rust/Cargo.toml

  - name: ccr-cancel-stream-on-disconnect
    priority: P1
    dependencies: [ccr-cancel-add-tokio-util]
    prompt: |
      Update `stream_response_translated` in `contrib/ccr-rust/src/router.rs`
      to abort upstream when client disconnects:
      
      1. Import `tokio_util::sync::CancellationToken`
      
      2. In the spawned streaming task, use `tokio::select!` to monitor:
         ```rust
         tokio::select! {
             chunk = stream.next() => { /* handle chunk */ }
             _ = tx.closed() => {
                 tracing::debug!("Client disconnected, aborting upstream");
                 break;
             }
         }
         ```
      
      3. The `tx.closed()` future resolves when the response body is dropped.
      
      This prevents wasted bandwidth when clients disconnect mid-stream.
    verify_command: grep -q "tx.closed()\|client disconnect" contrib/ccr-rust/src/router.rs

  - name: ccr-cancel-log-reason
    priority: P1
    dependencies: [ccr-cancel-stream-on-disconnect]
    prompt: |
      Add cancellation logging to `contrib/ccr-rust/src/router.rs`:
      
      1. Track cancellation reason in the streaming loop:
         ```rust
         enum CancelReason {
             ClientDisconnect,
             ServerShutdown,
             Timeout,
         }
         ```
      
      2. Log with tier and stream duration:
         ```rust
         tracing::info!(
             tier = %tier_name,
             duration_ms = %elapsed.as_millis(),
             reason = ?cancel_reason,
             "Stream cancelled"
         );
         ```
      
      3. Add metric: `ccr_stream_cancellations_total{tier, reason}`
    verify_command: grep -q "Stream cancelled\|CancelReason" contrib/ccr-rust/src/router.rs

  # ==========================================================================
  # Phase 4: Rate Limit Handling (P1)
  # ==========================================================================

  - name: ccr-ratelimit-state-struct
    priority: P1
    prompt: |
      Create `contrib/ccr-rust/src/ratelimit.rs` with rate limit state:
      
      ```rust
      use parking_lot::RwLock;
      use std::collections::HashMap;
      use std::time::{Duration, Instant};
      
      #[derive(Debug, Default)]
      pub struct TierRateLimitState {
          pub remaining: Option<u32>,
          pub reset_at: Option<Instant>,
          pub backoff_until: Option<Instant>,
          pub consecutive_429s: u32,
      }
      
      #[derive(Default)]
      pub struct RateLimitTracker {
          tiers: RwLock<HashMap<String, TierRateLimitState>>,
      }
      
      impl RateLimitTracker {
          pub fn new() -> Self { Self::default() }
          
          pub fn should_skip_tier(&self, tier: &str) -> bool {
              let tiers = self.tiers.read();
              if let Some(state) = tiers.get(tier) {
                  if let Some(until) = state.backoff_until {
                      if Instant::now() < until { return true; }
                  }
              }
              false
          }
      }
      ```
      
      Add `pub mod ratelimit;` to `src/lib.rs`.
    verify_command: grep -q "RateLimitTracker\|TierRateLimitState" contrib/ccr-rust/src/ratelimit.rs

  - name: ccr-ratelimit-record-429
    priority: P1
    dependencies: [ccr-ratelimit-state-struct]
    prompt: |
      Add 429 handling to `contrib/ccr-rust/src/ratelimit.rs`:
      
      ```rust
      impl RateLimitTracker {
          pub fn record_429(&self, tier: &str, retry_after: Option<Duration>) {
              let mut tiers = self.tiers.write();
              let state = tiers.entry(tier.to_string()).or_default();
              state.consecutive_429s += 1;
              
              // Exponential backoff: 1s, 2s, 4s, 8s... capped at 60s
              let base_backoff = retry_after.unwrap_or(Duration::from_secs(1));
              let multiplier = 2u32.saturating_pow(state.consecutive_429s.min(6));
              let backoff = base_backoff.saturating_mul(multiplier).min(Duration::from_secs(60));
              
              state.backoff_until = Some(Instant::now() + backoff);
              
              tracing::warn!(
                  tier = %tier,
                  backoff_secs = %backoff.as_secs(),
                  consecutive = %state.consecutive_429s,
                  "Rate limited, backing off"
              );
          }
          
          pub fn record_success(&self, tier: &str) {
              let mut tiers = self.tiers.write();
              if let Some(state) = tiers.get_mut(tier) {
                  state.consecutive_429s = 0;
                  state.backoff_until = None;
              }
          }
      }
      ```
    verify_command: grep -q "record_429\|consecutive_429s" contrib/ccr-rust/src/ratelimit.rs

  - name: ccr-ratelimit-integrate-router
    priority: P1
    dependencies: [ccr-ratelimit-record-429]
    prompt: |
      Integrate rate limit tracking into `contrib/ccr-rust/src/router.rs`:
      
      1. Add to `AppState`:
         ```rust
         pub ratelimit_tracker: Arc<RateLimitTracker>,
         ```
      
      2. Initialize in `main.rs`:
         ```rust
         ratelimit_tracker: Arc::new(RateLimitTracker::new()),
         ```
      
      3. In `handle_messages`, before trying a tier:
         ```rust
         if state.ratelimit_tracker.should_skip_tier(tier_name) {
             tracing::debug!(tier = %tier_name, "Skipping rate-limited tier");
             continue;
         }
         ```
      
      4. In `try_request`, on 429 response:
         ```rust
         if resp.status() == StatusCode::TOO_MANY_REQUESTS {
             let retry_after = resp.headers()
                 .get("retry-after")
                 .and_then(|v| v.to_str().ok())
                 .and_then(|s| s.parse::<u64>().ok())
                 .map(Duration::from_secs);
             state.ratelimit_tracker.record_429(tier_name, retry_after);
         }
         ```
      
      5. On success, call `record_success(tier_name)`.
    verify_command: grep -q "ratelimit_tracker\|should_skip_tier" contrib/ccr-rust/src/router.rs

  - name: ccr-ratelimit-metrics
    priority: P1
    dependencies: [ccr-ratelimit-integrate-router]
    prompt: |
      Add rate limit metrics to `contrib/ccr-rust/src/metrics.rs`:
      
      ```rust
      lazy_static! {
          static ref RATE_LIMIT_HITS: IntCounterVec = register_int_counter_vec!(
              "ccr_rate_limit_hits_total",
              "Number of 429 responses received",
              &["tier"]
          ).unwrap();
          
          static ref RATE_LIMIT_SKIPS: IntCounterVec = register_int_counter_vec!(
              "ccr_rate_limit_skips_total",
              "Number of requests skipped due to rate limit backoff",
              &["tier"]
          ).unwrap();
      }
      
      pub fn record_rate_limit_hit(tier: &str) {
          RATE_LIMIT_HITS.with_label_values(&[tier]).inc();
      }
      
      pub fn record_rate_limit_skip(tier: &str) {
          RATE_LIMIT_SKIPS.with_label_values(&[tier]).inc();
      }
      ```
      
      Call these from ratelimit.rs when recording 429s and skips.
    verify_command: grep -q "rate_limit_hits_total\|rate_limit_skips_total" contrib/ccr-rust/src/metrics.rs

  # ==========================================================================
  # Phase 5: Think-Tag Stripping (P1)
  # ==========================================================================

  - name: ccr-thinktag-regex-strip
    priority: P1
    prompt: |
      Add think-tag stripping to `contrib/ccr-rust/src/transformer.rs`:
      
      Create `ThinkTagTransformer`:
      
      ```rust
      use regex::Regex;
      use lazy_static::lazy_static;
      
      lazy_static! {
          static ref THINK_TAG_REGEX: Regex = Regex::new(
              r"(?s)<(think|thinking|reasoning)>.*?</\1>"
          ).unwrap();
      }
      
      #[derive(Debug, Clone)]
      pub struct ThinkTagTransformer;
      
      impl Transformer for ThinkTagTransformer {
          fn name(&self) -> &str { "thinktag" }
          
          fn transform_response(&self, mut response: Value) -> Result<Value> {
              if let Some(content) = response.get_mut("content") {
                  if let Some(arr) = content.as_array_mut() {
                      for block in arr {
                          if let Some(text) = block.get_mut("text") {
                              if let Some(s) = text.as_str() {
                                  let stripped = THINK_TAG_REGEX.replace_all(s, "").to_string();
                                  *text = Value::String(stripped.trim().to_string());
                              }
                          }
                      }
                  }
              }
              Ok(response)
          }
      }
      ```
      
      Add `regex = "1"` to Cargo.toml if not present.
    verify_command: grep -q "ThinkTagTransformer\|THINK_TAG_REGEX" contrib/ccr-rust/src/transformer.rs

  - name: ccr-thinktag-register
    priority: P1
    dependencies: [ccr-thinktag-regex-strip]
    prompt: |
      Register `ThinkTagTransformer` in `contrib/ccr-rust/src/transformer.rs`:
      
      In `TransformerRegistry::new()`, add:
      ```rust
      registry.register("thinktag", Arc::new(ThinkTagTransformer));
      ```
      
      Also update the README transformers table to include:
      ```
      | `thinktag` | Strip `<think>`, `<thinking>`, `<reasoning>` blocks |
      ```
    verify_command: "grep -q 'thinktag.*ThinkTagTransformer' contrib/ccr-rust/src/transformer.rs"

  - name: ccr-thinktag-tests
    priority: P1
    dependencies: [ccr-thinktag-register]
    prompt: |
      Add tests for ThinkTagTransformer in `contrib/ccr-rust/src/transformer.rs`:
      
      ```rust
      #[test]
      fn thinktag_strips_think_blocks() {
          let transformer = ThinkTagTransformer;
          let response = serde_json::json!({
              "content": [{"type": "text", "text": "Before <think>internal reasoning</think> After"}]
          });
          let result = transformer.transform_response(response).unwrap();
          assert_eq!(result["content"][0]["text"], "Before  After");
      }
      
      #[test]
      fn thinktag_strips_thinking_blocks() {
          let transformer = ThinkTagTransformer;
          let response = serde_json::json!({
              "content": [{"type": "text", "text": "<thinking>step 1\nstep 2</thinking>\nFinal answer"}]
          });
          let result = transformer.transform_response(response).unwrap();
          assert_eq!(result["content"][0]["text"], "Final answer");
      }
      
      #[test]
      fn thinktag_preserves_non_think_content() {
          let transformer = ThinkTagTransformer;
          let response = serde_json::json!({
              "content": [{"type": "text", "text": "No thinking here"}]
          });
          let result = transformer.transform_response(response).unwrap();
          assert_eq!(result["content"][0]["text"], "No thinking here");
      }
      ```
    verify_command: "cd contrib/ccr-rust && cargo test thinktag 2>&1 | grep -q 'ok'"

  # ==========================================================================
  # Phase 6: Tool Result Translation (P1)
  # ==========================================================================

  - name: ccr-tool-result-anthropic-to-openai
    priority: P1
    prompt: |
      Extend `translate_request_anthropic_to_openai` in `contrib/ccr-rust/src/router.rs`
      to handle tool_result messages:
      
      Anthropic sends tool results in user messages:
      ```json
      {"role": "user", "content": [{"type": "tool_result", "tool_use_id": "toolu_123", "content": "result"}]}
      ```
      
      OpenAI expects:
      ```json
      {"role": "tool", "tool_call_id": "toolu_123", "content": "result"}
      ```
      
      In the message conversion loop:
      1. Check if content is an array with `tool_result` blocks
      2. For each `tool_result`, emit a separate message with role="tool"
      3. Keep any non-tool_result content as a user message
      
      ```rust
      if let Some(arr) = msg.content.as_array() {
          for block in arr {
              if block.get("type") == Some(&json!("tool_result")) {
                  messages.push(OpenAIMessage {
                      role: "tool".to_string(),
                      content: block.get("content").and_then(|c| c.as_str()).map(String::from),
                      tool_call_id: block.get("tool_use_id").and_then(|id| id.as_str()).map(String::from),
                      ..Default::default()
                  });
              }
          }
      }
      ```
    verify_command: grep -q "tool_result\|tool_call_id" contrib/ccr-rust/src/router.rs

  - name: ccr-tool-result-test
    priority: P1
    dependencies: [ccr-tool-result-anthropic-to-openai]
    prompt: |
      Add test for tool_result translation in `contrib/ccr-rust/src/router.rs`:
      
      ```rust
      #[test]
      fn test_translate_tool_result() {
          let request = AnthropicRequest {
              model: "claude-3".to_string(),
              messages: vec![
                  Message {
                      role: "user".to_string(),
                      content: serde_json::json!("What's 2+2?"),
                  },
                  Message {
                      role: "assistant".to_string(),
                      content: serde_json::json!([{
                          "type": "tool_use",
                          "id": "toolu_123",
                          "name": "calculator",
                          "input": {"expression": "2+2"}
                      }]),
                  },
                  Message {
                      role: "user".to_string(),
                      content: serde_json::json!([{
                          "type": "tool_result",
                          "tool_use_id": "toolu_123",
                          "content": "4"
                      }]),
                  },
              ],
              system: None,
              max_tokens: Some(1000),
              temperature: None,
              stream: None,
              tools: None,
          };
          
          let openai_req = translate_request_anthropic_to_openai(&request, "gpt-4");
          
          // Should have: user, assistant, tool messages
          let tool_msg = openai_req.messages.iter()
              .find(|m| m.role == "tool")
              .expect("Should have tool message");
          assert_eq!(tool_msg.content, Some("4".to_string()));
      }
      ```
    verify_command: "cd contrib/ccr-rust && cargo test test_translate_tool_result 2>&1 | grep -q 'ok'"

  # ==========================================================================
  # Phase 7: Documentation (P2)
  # ==========================================================================

  - name: ccr-docs-api-reference
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/api.md` documenting all endpoints:
      
      # CCR-Rust API Reference
      
      ## Endpoints
      
      ### POST /v1/messages
      Main chat completion endpoint. Accepts Anthropic-format requests.
      
      **Request:**
      ```json
      {
        "model": "claude-3-opus",
        "messages": [{"role": "user", "content": "Hello"}],
        "max_tokens": 1024
      }
      ```
      
      **Response Headers:**
      - `x-ccr-tier`: Which backend tier served the request
      
      ### GET /v1/usage
      Returns aggregate token usage per tier.
      
      ### GET /v1/latencies  
      Returns EWMA latency stats per tier.
      
      ### GET /v1/token-drift
      Returns token estimation accuracy metrics.
      
      ### GET /metrics
      Prometheus scrape endpoint.
      
      ### GET /health
      Returns "ok" if server is running.
      
      Include curl examples for each endpoint.
    verify_command: test -f contrib/ccr-rust/docs/api.md

  - name: ccr-docs-transformers
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/transformers.md` documenting the transformer system:
      
      # CCR-Rust Transformers
      
      ## Overview
      Transformers modify requests before sending to providers and responses
      before returning to clients.
      
      ## Configuration
      
      ```json
      {
        "transformer": {
          "use": ["anthropic-to-openai", ["maxtoken", {"max_tokens": 65536}]],
          "deepseek-reasoner": { "use": ["reasoning", "thinktag"] }
        }
      }
      ```
      
      ## Built-in Transformers
      
      | Name | Description | Options |
      |------|-------------|---------|
      | `identity` | No-op passthrough | None |
      | `anthropic` | Anthropic format handling | None |
      | `anthropic-to-openai` | Tool definition conversion | None |
      | `deepseek` | DeepSeek-specific normalization | None |
      | `openrouter` | OpenRouter format handling | None |
      | `tooluse` | Add IDs to tool blocks | None |
      | `maxtoken` | Cap/set max_tokens | `max_tokens: u32` |
      | `reasoning` | Convert reasoning_content | None |
      | `enhancetool` | Add cache_control metadata | None |
      | `thinktag` | Strip think/thinking/reasoning tags | None |
      
      ## Request/Response Flow
      
      Request: Client → transformers (forward) → Provider
      Response: Provider → transformers (reverse) → Client
    verify_command: test -f contrib/ccr-rust/docs/transformers.md

  - name: ccr-docs-configuration
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/configuration.md` with full config reference:
      
      # CCR-Rust Configuration
      
      ## Config File Location
      - CLI: `--config path/to/config.json`
      - Environment: `CCR_CONFIG=path/to/config.json`
      - Default: `~/.claude-code-router/config.json`
      
      ## Full Schema
      
      ```json
      {
        "Providers": [
          {
            "name": "provider-name",
            "api_base_url": "https://api.example.com/v1",
            "api_key": "sk-...",
            "models": ["model-a", "model-b"],
            "transformer": { "use": ["..."] }
          }
        ],
        "Router": {
          "default": "provider,model",
          "think": "provider,model",
          "longContext": "provider,model",
          "longContextThreshold": 60000,
          "tierRetries": {
            "tier-0": { "max_retries": 3, "base_backoff_ms": 100 }
          }
        }
      }
      ```
      
      ## Per-Tier Retry Config
      
      | Field | Type | Default | Description |
      |-------|------|---------|-------------|
      | max_retries | u32 | 3 | Max attempts per tier |
      | base_backoff_ms | u64 | 100 | Initial backoff |
      | backoff_multiplier | f64 | 2.0 | Exponential factor |
      | max_backoff_ms | u64 | 10000 | Backoff cap |
    verify_command: test -f contrib/ccr-rust/docs/configuration.md

  - name: ccr-docs-troubleshooting
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/troubleshooting.md`:
      
      # Troubleshooting CCR-Rust
      
      ## Connection Issues
      
      **"Connection refused"**
      - Check provider URL in config
      - Verify API endpoint is accessible
      - Check firewall rules
      
      **SSL/TLS errors**
      - Ensure system CA certificates are installed
      - Try with `RUST_LOG=reqwest=debug` for details
      
      ## Rate Limiting
      
      **Frequent 429 errors**
      - Check `/v1/latencies` for affected tiers
      - Monitor `ccr_rate_limit_hits_total` metric
      - Increase `base_backoff_ms` in config
      
      ## Format Translation
      
      **Tool calls not working**
      - Ensure transformer chain includes `anthropic-to-openai`
      - Check provider supports function calling
      
      **Missing system prompt**
      - Anthropic `system` field is auto-converted to OpenAI format
      - Verify it's not being filtered by provider
      
      ## Performance
      
      **High latency**
      - Check `/v1/latencies` for slow tiers
      - EWMA will auto-reorder, but may take 3+ requests
      - Consider adjusting tier order in config
      
      ## Debugging
      
      ```bash
      # Enable debug logging
      RUST_LOG=ccr_rust=debug,tower_http=debug ./ccr-rust
      
      # Check metrics
      curl localhost:3456/metrics | grep ccr_
      
      # Test health
      curl localhost:3456/health
      ```
    verify_command: test -f contrib/ccr-rust/docs/troubleshooting.md

  - name: ccr-docs-deployment
    priority: P2
    prompt: |
      Create `contrib/ccr-rust/docs/deployment.md`:
      
      # Deploying CCR-Rust
      
      ## Building
      
      ```bash
      cargo build --release
      # Binary at target/release/ccr-rust
      ```
      
      ## Systemd (Linux)
      
      ```ini
      [Unit]
      Description=Claude Code Router (Rust)
      After=network.target
      
      [Service]
      Type=simple
      User=ccr
      ExecStart=/usr/local/bin/ccr-rust --config /etc/ccr/config.json
      Restart=always
      Environment=RUST_LOG=info
      
      [Install]
      WantedBy=multi-user.target
      ```
      
      ## Docker
      
      ```dockerfile
      FROM rust:1.75 AS builder
      WORKDIR /app
      COPY . .
      RUN cargo build --release
      
      FROM debian:bookworm-slim
      RUN apt-get update && apt-get install -y ca-certificates && rm -rf /var/lib/apt/lists/*
      COPY --from=builder /app/target/release/ccr-rust /usr/local/bin/
      ENTRYPOINT ["ccr-rust"]
      ```
      
      ## Kubernetes
      
      See `k8s/` directory for manifests.
      
      ## Security
      
      - Run as non-root user
      - Store API keys in secrets, not config files
      - Use TLS termination at load balancer
    verify_command: test -f contrib/ccr-rust/docs/deployment.md

  # ==========================================================================
  # Phase 8: Testing (P2)
  # ==========================================================================

  - name: ccr-test-ratelimit-unit
    priority: P2
    dependencies: [ccr-ratelimit-integrate-router]
    prompt: |
      Add unit tests for rate limiting in `contrib/ccr-rust/src/ratelimit.rs`:
      
      ```rust
      #[cfg(test)]
      mod tests {
          use super::*;
          
          #[test]
          fn test_should_skip_new_tier() {
              let tracker = RateLimitTracker::new();
              assert!(!tracker.should_skip_tier("tier-0"));
          }
          
          #[test]
          fn test_skip_after_429() {
              let tracker = RateLimitTracker::new();
              tracker.record_429("tier-0", None);
              assert!(tracker.should_skip_tier("tier-0"));
          }
          
          #[test]
          fn test_success_clears_backoff() {
              let tracker = RateLimitTracker::new();
              tracker.record_429("tier-0", None);
              tracker.record_success("tier-0");
              // After success, consecutive count resets
              let tiers = tracker.tiers.read();
              assert_eq!(tiers.get("tier-0").unwrap().consecutive_429s, 0);
          }
          
          #[test]
          fn test_exponential_backoff() {
              let tracker = RateLimitTracker::new();
              tracker.record_429("tier-0", None);
              tracker.record_429("tier-0", None);
              let tiers = tracker.tiers.read();
              assert_eq!(tiers.get("tier-0").unwrap().consecutive_429s, 2);
          }
      }
      ```
    verify_command: "cd contrib/ccr-rust && cargo test ratelimit::tests 2>&1 | grep -q 'ok'"

  - name: ccr-test-shutdown-integration
    priority: P2
    dependencies: [ccr-shutdown-graceful-serve]
    prompt: |
      Add integration test for graceful shutdown in `contrib/ccr-rust/tests/test_shutdown.rs`:
      
      ```rust
      use std::time::Duration;
      use tokio::time::timeout;
      
      #[tokio::test]
      async fn test_graceful_shutdown_waits_for_streams() {
          // This test verifies behavior, not actual signals
          // We test the shutdown logic components
          
          let active_count = std::sync::atomic::AtomicUsize::new(1);
          
          // Simulate checking for active streams
          let has_active = active_count.load(std::sync::atomic::Ordering::Relaxed) > 0;
          assert!(has_active, "Should detect active streams");
          
          // Simulate stream completing
          active_count.store(0, std::sync::atomic::Ordering::Relaxed);
          let has_active = active_count.load(std::sync::atomic::Ordering::Relaxed) > 0;
          assert!(!has_active, "Should detect no active streams after completion");
      }
      ```
    verify_command: "cd contrib/ccr-rust && cargo test test_shutdown 2>&1 | grep -q 'test result'"

  # ==========================================================================
  # Phase 9: Cleanup (P3)
  # ==========================================================================

  - name: ccr-cleanup-unused-fields
    priority: P3
    prompt: |
      Fix dead code warnings in `contrib/ccr-rust/src/router.rs`:
      
      Add `#[allow(dead_code)]` with TODO comments for future use:
      
      ```rust
      #[derive(Debug, Deserialize)]
      struct OpenAIResponse {
          id: String,
          #[allow(dead_code)] // TODO: Log for debugging
          object: String,
          #[allow(dead_code)] // TODO: Include in response headers
          created: i64,
          #[allow(dead_code)] // TODO: Validate model matches requested
          model: String,
          choices: Vec<OpenAIChoice>,
          usage: Option<OpenAIUsage>,
      }
      ```
      
      Apply similar annotations to other unused fields in:
      - `OpenAIChoice.index`
      - `OpenAIResponseMessage.role`
      - `OpenAIUsage.prompt_tokens_details`
      - `OpenAIStreamChunk` fields
      - `OpenAIDelta.role`
    verify_command: "cd contrib/ccr-rust && cargo check 2>&1 | grep -c 'warning:.*never read' | xargs test 0 -eq"

  - name: ccr-cleanup-unused-functions
    priority: P3
    prompt: |
      Fix dead code warnings for unused functions in `contrib/ccr-rust/src/`:
      
      In `router.rs`:
      - `build_transformer_chain` is defined but never called
      - Either integrate it into the request flow or remove it
      
      In `transformer.rs`:
      - `TransformerChain.len()` and `is_empty()` may be test-only
      - Add `#[cfg(test)]` or `#[allow(dead_code)]` as appropriate
      
      In `config.rs`:
      - `provider_transformers()` and `is_sole_transformer()` are unused
      - Either integrate or add `#[allow(dead_code)]` with TODO
      
      Goal: `cargo check 2>&1 | grep -c warning` should be 0.
    verify_command: "cd contrib/ccr-rust && cargo check 2>&1 | grep -c 'warning:' | xargs test 5 -gt"

  - name: ccr-cleanup-remove-old-sse-function
    priority: P3
    prompt: |
      Remove unused `stream_response` function from `contrib/ccr-rust/src/sse.rs`:
      
      1. Check if `stream_response` is called anywhere:
         `grep -r "stream_response\b" --include="*.rs" contrib/ccr-rust/src/`
      
      2. If not used (only `stream_response_translated` is used), remove:
         - The `stream_response` function
         - Any helper functions only used by it
      
      3. Keep:
         - `StreamVerifyCtx` (used by router)
         - `extract_usage_from_event` (used by router)
         - Tests for kept functionality
      
      4. Update `pub` exports if needed.
    verify_command: "grep -c 'pub async fn stream_response[^_]' contrib/ccr-rust/src/sse.rs | xargs test 0 -eq"
